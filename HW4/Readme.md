# Спектральна кластеризація

Спектральна кластеризація — це один із підходів для кластеризації даних, який допомагає знайти складні структури в даних, особливо якщо кластери не розділяються лінійно. У цій роботі я спробую пояснити теоретичну частину спектральної кластеризації і показати, чим вона відрізняється від алгоритму k-середніх.

## Основи спектральної кластеризації

### 1. Побудова графа подібності
- Кожну точку в даних можна представити як вузол графа.
- Між вузлами встановлюються зв'язки, які відображають подібність або близькість між точками (зазвичай за допомогою функції ядра, наприклад, гаусового).
- На основі цього будується матриця подібності, яка показує, наскільки сильно пов'язані точки між собою.

### 2. Матриця Лапласа
- Щоб побудувати матрицю Лапласа, потрібно знати ступінь кожного вузла, який записується в діагональну матрицю \(D\), і матрицю подібності \(W\).
- Формула для матриці Лапласа виглядає так: \(L = D - W\).
- Ця матриця використовується, щоб дослідити структуру графа та виявити, як точки даних пов'язані між собою.

### 3. Спектральний розклад
- Наступний крок — обчислити власні значення та власні вектори матриці Лапласа.
- Власні вектори, що відповідають найменшим власним значенням, несуть інформацію про те, як згруповані точки.

### 4. Проєкція даних
- Точки переносяться в новий простір, що базується на власних векторах, з меншою розмірністю. У цьому просторі дані часто стають легше розділити на кластери.

### 5. Кластеризація в новому просторі
- Після проєкції можна застосувати стандартний алгоритм кластеризації, наприклад, k-середніх, для групування точок.

## Переваги спектральної кластеризації над k-середніх
- **Розпізнає нелінійні структури**: Спектральна кластеризація здатна виявляти складні форми кластерів, які важко побачити за допомогою простих алгоритмів.
- **Аналіз глобальної структури**: Цей метод бере до уваги загальні зв’язки в даних через спектральні властивості графа.
- **Гнучкість у виборі міри подібності**: Можна обрати різні функції ядра, що дає можливість налаштовувати метод під конкретні дані.

## Недоліки спектральної кластеризації
- **Обчислювально затратна**: Визначення власних векторів займає багато ресурсів, особливо при великій кількості даних.
- **Налаштування параметрів**: Потрібно визначити кількість сусідів у графі та обрати параметри функції ядра.
- **Складно масштабувати**: Для великих наборів даних цей метод не такий ефективний, як k-середніх.

## Порівняння з алгоритмом k-середніх

### Алгоритм k-середніх
**Переваги**:
- Простий у використанні та швидкий.
- Працює добре для великих наборів даних, якщо кластери мають просту форму.

**Недоліки**:
- Передбачає, що кластери мають однаковий розмір та форму.
- Чутливий до вибору початкових центрів кластерів і викидів.
- Не виявляє кластери зі складною нелінійною структурою.

### Спектральна кластеризація
**Переваги**:
- Може знайти кластери будь-якої форми.
- Менш залежить від викидів і початкових умов.

**Недоліки**:
- Потребує більше обчислювальних ресурсів.
- Складніша в реалізації та виборі параметрів.

## Висновки
Спектральна кластеризація може бути корисною, коли дані мають складну структуру, де k-середніх не справляється. Цей метод дозволяє знаходити складні форми кластерів та враховувати загальні властивості даних, але вимагає більше обчислювальних ресурсів і ретельного налаштування параметрів.

### Рекомендації
- Використовувати спектральну кластеризацію, якщо невідомо, яку форму мають кластери.
- Для великих наборів даних, де важлива швидкість, краще використовувати k-середніх або його варіанти.
- По можливості порівнювати результати різних методів для кращого розуміння структури даних.
