# Метод Опорних Векторів (SVM)

## Зміст
1. [Огляд](#огляд)
2. [Принцип Роботи SVM](#принцип-роботи-svm)
3. [Основні Параметри SVM](#основні-параметри-svm)
4. [Зв'язок Параметрів з Теорією та Вплив на Продуктивність](#зв'язок-параметрів-з-теорією-та-вплив-на-продуктивність)
    - [Параметр C](#параметр-c)
    - [Ядро (kernel)](#ядро-kernel)
    - [Gamma](#gamma)
    - [Ступінь (degree)](#ступінь-degree)
5. [Результати та Висновки](#результати-та-висновки)

## Огляд

Метод опорних векторів (SVM) є одним із найпотужніших алгоритмів для задач класифікації та регресії. Використовуючи бібліотеку [`sklearn.svm`](https://scikit-learn.org/stable/modules/svm.html), можна ефективно застосовувати SVM до різноманітних задач машинного навчання. У цьому документі ми детально розглянемо принцип роботи SVM, налаштування його параметрів, їх зв'язок з теоретичними аспектами алгоритму та вплив на продуктивність моделі.

## Принцип Роботи SVM

SVM прагне знайти гіперплощину, яка максимально розділяє класи в просторі ознак. Основна мета — **максимізувати маржу**, тобто відстань між найближчими точками різних класів та гіперплощиною. Точки, які лежать на межі цієї маржі, називаються **опорними векторами**.

## Основні Параметри SVM

- **C**: Параметр регуляризації, що контролює компроміс між максимізацією маржі та допустимими помилками класифікації.
- **kernel**: Тип ядра, яке визначає функцію подібності для перетворення даних у вищий вимірний простір.
  - **Варіанти**:
    - `'linear'`: Лінійне ядро
    - `'poly'`: Поліноміальне ядро
    - `'rbf'`: Радіальна базисна функція
    - `'sigmoid'`: Сигмоїдне ядро
- **gamma**: Параметр, що визначає вплив окремих тренувальних прикладів для деяких ядер.
- **degree**: Ступінь полінома для поліноміального ядра.
- **coef0**: Незалежний член у поліноміальному та сигмоїдному ядрах.

## Зв'язок Параметрів з Теорією та Вплив на Продуктивність

### Параметр C

- **Теоретичний аспект**: Визначає, наскільки модель штрафується за неправильну класифікацію тренувальних прикладів. Велике значення C намагається мінімізувати помилки, що може призвести до перенавчання.
- **Вплив на роботу**:
  - **Високе C**: Модель намагається класифікувати всі тренувальні дані правильно, що може призвести до перенавчання.
  - **Низьке C**: Допускає деякі помилки в тренувальних даних, що може покращити узагальнення на тестових даних.

### Ядро (kernel)

- **Теоретичний аспект**: Ядрові функції дозволяють алгоритму працювати в вищому вимірному просторі без явного перетворення ознак (Kernel Trick).
- **Вплив на роботу**:
  - `'linear'`: Використовується, коли дані лінійно роздільні.
  - `'rbf'`: Добре працює з нелінійними даними.
  - `'sigmoid'`: Використовується для моделювання нелінійних взаємозв'язків, подібних до нейронних мереж.
  - `'poly'`: Підходить для даних з поліноміальними взаємозв'язками.

### Gamma

- **Теоретичний аспект**: Визначає вплив окремих тренувальних прикладів. Маленьке gamma означає далеке поширення впливу, велике gamma — близьке.
- **Вплив на роботу**:
  - **Високе gamma**: Модель сильно реагує на ближні точки, що може призвести до перенавчання.
  - **Низьке gamma**: Модель стає більш гладкою, може недонавчатися.

### Ступінь (degree)

- **Теоретичний аспект**: Ступінь полінома в поліноміальному ядрі.
- **Вплив на роботу**:
  - **Високий degree**: Модель може захоплювати складні патерни, але ризикує перенавчитися.
  - **Низький degree**: Модель більш проста, може недонавчатися.

## Результати та Висновки

Після налаштування параметрів SVM було проведено тренування моделі. Нижче наведено зразок логів тренування та результати класифікації.

### Логи Тренування

```
багато подібних логів
[CV 31/32] END C=100000, degree=10, gamma=1e-05, kernel=linear;, score=1.000 total time=   0.0s
[CV 32/32] END C=100000, degree=10, gamma=1e-05, kernel=linear;, score=1.000 total time=   0.0s
Найкращі параметри:
{'C': 1, 'degree': 3, 'gamma': 1, 'kernel': 'poly'}
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        15
           1       0.89      0.89      0.89        18
           2       0.90      0.90      0.90        20

    accuracy                           0.92        53
   macro avg       0.93      0.93      0.93        53
weighted avg       0.92      0.92      0.92        53


Process finished with exit code 0
```
### Висновки
Метод опорних векторів є ефективним інструментом для задач класифікації та регресії. Правильний вибір параметрів, таких як C, kernel, gamma та degree, має вирішальне значення для продуктивності моделі. У цьому проекті було показано, як налаштувати ці параметри та оцінити модель на реальних даних.





